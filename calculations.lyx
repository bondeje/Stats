#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1cm
\topmargin 1cm
\rightmargin 1cm
\bottommargin 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section*
basic_statistics.h
\end_layout

\begin_layout Standard
Module notes:
\end_layout

\begin_layout Standard
the 
\begin_inset Formula $weights$
\end_inset

 parameter in the context of this module are not to be interpreted as frequencie
s of occurrence but rather weighting based on estimated error or some pre-determ
ined or subjective quality factors.In most cases, 
\begin_inset Formula $weights$
\end_inset

 should just be set to NULL.
 For such cases of frequency, a histogram object is appropriate, which has
 separate implementations of some of these methods.
 Do not use frequency as weights; the answer will be wrong.
 Even in most cases of using an estimated error, that error bar is somewhat
 inappropriate to use as weights and a more appropriate application is to
 scale the data itself by the error into a 
\begin_inset Formula $z-$
\end_inset

score, then apply these functions and finally re-multiply by the error to
 get the (local) mean/covariance/variance, etc.
\end_layout

\begin_layout Subsubsection*
double mean(double * data, size_t n, double * weights)
\end_layout

\begin_layout Standard
Setting weights to NULL calculates the same as if the weights were all equal
 to some value.
 We take as a general linear estimator having the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
y & = & \frac{1}{A}\sum_{i=0}^{n-1}w_{i}x_{i}
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $x_{i}$
\end_inset

 are i.i.d.
 r.v.s.
 This weighting implies no correlation is introduced between variables,
 i.e.
 the weights could in theory have matrix form 
\begin_inset Formula $w_{ij}$
\end_inset

 with 
\begin_inset Formula $w_{ij}\neq0$
\end_inset

, but then this is altering covariance and independence.
 In these cases, the underlying formulas will have errors and you must use
 the specialized whitening/de-whitening functionality.
 Moving along, 
\begin_inset Formula 
\begin{eqnarray*}
\mathbb{E}[y] & = & \frac{1}{A}\sum_{i=0}^{n-1}w_{i}\mathbb{E}[x_{i}]\\
 & = & \frac{\mu}{A}\sum_{i=0}^{n-1}w_{i}.
\end{eqnarray*}

\end_inset

Since we want 
\begin_inset Formula $\mathbb{E}[y]$
\end_inset

 to be an unbiased estimate of the mean of 
\begin_inset Formula $x$
\end_inset

, then this constrains 
\begin_inset Formula $A$
\end_inset

 to be 
\begin_inset Formula 
\begin{eqnarray*}
A & = & \sum_{i=0}^{n-1}w_{i}
\end{eqnarray*}

\end_inset

or
\begin_inset Formula 
\begin{eqnarray*}
\hat{\mu} & = & \frac{1}{{\displaystyle \sum_{i=0}^{n-1}w_{i}}}\sum_{i=0}^{n-1}w_{i}x_{i}
\end{eqnarray*}

\end_inset

We obviously see that for the case 
\begin_inset Formula $w_{i}=w$
\end_inset

 (independent of observation), the estimate 
\begin_inset Formula $\hat{\mu}$
\end_inset

 reduces to the normal estimate.
 
\end_layout

\begin_layout Subsubsection*
double variance(double * data, size_t n, double * weights)
\end_layout

\begin_layout Standard
Variance is calculated as the case of covariance with 
\begin_inset Formula $data=ref$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
double stddev(double * data, size_t n, double * weights)
\end_layout

\begin_layout Standard
This simply takes 
\begin_inset Formula $\sqrt{variance}$
\end_inset

for now.
 Eventually a ddof parameter will be added which will default to 1 to allow
 for approximations to the true unbiased stddev, which ultimately is distributio
n dependent.
\end_layout

\begin_layout Subsubsection*
double covariance(double * data, double * ref, size_t n, double * weights)
\end_layout

\begin_layout Standard
Following much the same calculation as the mean
\begin_inset Formula 
\begin{eqnarray*}
z & = & \frac{1}{A}\sum_{i=0}^{n-1}w_{i}(x_{i}-\hat{\mu}(x))(y_{i}-\hat{\mu}(y)\\
\mathbb{E}[z] & = & \sigma_{xy}\\
 & = & \frac{1}{A}\sum_{i=0}^{n-1}w_{i}\mathbb{E}\left[(x_{i}-\hat{\mu}(x))(y_{i}-\hat{\mu}(y)\right]\\
 & = & \frac{1}{A}\sum_{i=0}^{n-1}w_{i}\mathbb{E}\left[\left(x_{i}-\frac{1}{{\displaystyle \sum_{j=0}^{n-1}w_{j}}}\sum_{j=0}^{n-1}w_{j}x_{j}\right)\left(y_{i}-\frac{1}{{\displaystyle \sum_{k=0}^{n-1}w_{k}}}\sum_{k=0}^{n-1}w_{k}y_{k}\right)\right]\\
 & = & \frac{1}{A}\sum_{i=0}^{n-1}w_{i}\mathbb{E}\left[x_{i}y_{i}-\frac{1}{{\displaystyle \sum_{j=0}^{n-1}w_{j}}}\sum_{j=0}^{n-1}w_{j}x_{j}y_{i}-\frac{1}{{\displaystyle \sum_{k=0}^{n-1}w_{k}}}\sum_{k=0}^{n-1}w_{k}x_{i}y_{k}+\left(\frac{1}{{\displaystyle \sum_{j=0}^{n-1}w_{j}}}\right)^{2}\sum_{j=0}^{n-1}\sum_{k=0}^{n-1}w_{j}w_{k}x_{j}y_{k}\right]\\
 & = & \frac{1}{A}\left[\sum_{i=0}^{n-1}w_{i}\mathbb{E}[x_{i}y_{i}]-\frac{1}{{\displaystyle \sum_{j=0}^{n-1}w_{j}}}\sum_{i=0}^{n-1}w_{i}\sum_{j=0}^{n-1}w_{j}\mathbb{E}[x_{j}y_{i}]-\frac{1}{{\displaystyle \sum_{k=0}^{n-1}w_{k}}}\sum_{i=0}^{n-1}w_{i}\sum_{k=0}^{n-1}w_{k}\mathbb{E}[x_{i}y_{k}]+\frac{1}{{\displaystyle \sum_{j=0}^{n-1}w_{j}}}\sum_{j=0}^{n-1}\sum_{k=0}^{n-1}w_{j}w_{k}\mathbb{E}[x_{j}y_{k}]\right]\\
 & = & \frac{1}{A}\frac{1}{{\displaystyle \sum_{j=0}^{n-1}w_{j}}}\left[\sum_{j=0}^{n-1}w_{j}\sum_{i=0}^{n-1}w_{i}(\sigma_{xy}+\mu_{x}\mu_{y})-\sum_{j=0}^{n-1}\sum_{k=0}^{n-1}w_{j}w_{k}(\sigma_{xy}\delta_{jk}+\mu_{x}\mu_{y}\right].
\end{eqnarray*}

\end_inset

If we consider the samples to be i.i.d., then 
\begin_inset Formula $Cov(x_{i},y_{j})=\sigma_{xy}\delta_{ij}$
\end_inset

 so that 
\begin_inset Formula $\mathbb{E}[x_{i}y_{j}]=\sigma_{xy}\delta_{ij}+\mathbb{E}[x_{i}]\mathbb{E}[y_{j}].$
\end_inset

If it weren't this would get quite complicated.
 Then we finally have
\begin_inset Formula 
\begin{eqnarray*}
\mathbb{E}[z] & = & \frac{1}{A}\frac{1}{{\displaystyle \sum_{i=0}^{n-1}w_{i}}}\left[(\sigma_{xy}+\mu_{x}\mu_{y})\left(\sum_{i=0}^{n-1}w_{i}\right)^{2}-\sum_{i=0}^{n-1}\sum_{j=0}^{n-1}w_{i}w_{j}\left(\sigma_{xy}\delta_{ij}+\mu_{x}\mu_{y}\right)\right]\\
 & = & \frac{\sigma_{xy}}{A}\frac{1}{{\displaystyle \sum_{i=0}^{n-1}w_{i}}}\left[\left(\sum_{i=0}^{n-1}w_{i}\right)^{2}-\sum_{i=0}^{n-1}w_{i}^{2}\right]
\end{eqnarray*}

\end_inset

and putting it all together, we get
\begin_inset Formula 
\begin{eqnarray*}
\hat{Cov}(x,y) & = & \frac{{\displaystyle 1}}{{\displaystyle \left(\sum_{i=0}^{n-1}w_{i}\right)^{2}-\sum_{i=0}^{n-1}w_{i}^{2}}}\left[\sum_{i=0}^{n-1}w_{i}\sum_{i=0}^{n-1}w_{i}x_{i}y_{i}-\sum_{j=0}^{n-1}w_{j}x_{j}\sum_{i=0}^{n-1}w_{i}y_{i}\right],
\end{eqnarray*}

\end_inset

which is an expression requiring tracking 5 quantities in a single loop.
 From here, variance estimation is trivially 
\begin_inset Formula $x=y$
\end_inset

.
 The expression matches the expected case of equal weights 
\begin_inset Formula $w_{i}=w$
\end_inset

,
\begin_inset Formula 
\begin{eqnarray*}
\hat{Cov}(x,y) & = & \frac{1}{{\displaystyle n-1}}\left[\sum_{i=0}^{n-1}x_{i}y_{i}-\sum_{j=0}^{n-1}x_{j}\sum_{i=0}^{n-1}y_{i}\right],
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsubsection*
double correlation(double * data, double * ref, size_t n, double * weights)
\end_layout

\begin_layout Standard
Using the weights sample covariance as a starting point and applying the
 sample standard deviation, or rather the square root of the unbiased sample
 variance,
\begin_inset Formula 
\begin{eqnarray*}
\hat{\rho}(x,y) & = & \frac{\hat{Cov}(x,y)}{\sqrt{\hat{Var}(x)}\sqrt{\hat{Var}(y)}}\\
 & = & \frac{\sum_{i=0}^{n-1}w_{i}\sum_{i=0}^{n-1}w_{i}x_{i}y_{i}-\sum_{j=0}^{n-1}w_{j}x_{j}\sum_{i=0}^{n-1}w_{i}y_{i}}{\sqrt{\sum_{i=0}^{n-1}w_{i}\sum_{i=0}^{n-1}w_{i}x_{i}^{2}-\left(\sum_{j=0}^{n-1}w_{j}x_{j}\right)^{2}}\sqrt{\sum_{i=0}^{n-1}w_{i}\sum_{i=0}^{n-1}w_{i}y_{i}^{2}-\left(\sum_{i=0}^{n-1}w_{i}y_{i}\right)^{2}}}\\
\text{if }x=y,\hat{\rho} & = & 1\\
\text{if }x=-y,\hat{\rho} & = & -1\\
\text{if }w_{i}=w,\hat{\rho}(x,y) & = & \frac{n\sum_{i=0}^{n-1}x_{i}y_{i}-\sum_{j=0}^{n-1}x_{j}\sum_{i=0}^{n-1}y_{i}}{\sqrt{n\sum_{i=0}^{n-1}x_{i}^{2}-\left(\sum_{j=0}^{n-1}x_{j}\right)^{2}}\sqrt{n\sum_{i=0}^{n-1}y_{i}^{2}-\left(\sum_{i=0}^{n-1}y_{i}\right)^{2}}}
\end{eqnarray*}

\end_inset

as expected/required.
\end_layout

\begin_layout Subsubsection*
double third_central_moment(double * data, size_t n, double * weights)
\end_layout

\begin_layout Standard
Following the same procedure as the mean and covariance,
\begin_inset Formula 
\begin{eqnarray*}
z & = & \frac{1}{A}\sum_{i=0}^{n-1}w_{i}(x_{i}-\hat{\mu}(x))^{3}\\
 & = & \frac{1}{A}\sum_{i=0}^{n-1}w_{i}(x_{i}^{3}-3x_{i}^{2}\hat{\mu}(x)+3x_{i}\hat{\mu}^{2}(x)-\hat{\mu}^{3}(x))\\
 & = & \frac{1}{A}\left(\sum_{i=0}^{n-1}w_{i}x_{i}^{3}-3\frac{1}{{\displaystyle \sum_{k=0}^{n-1}}w_{k}}\sum_{j=0}^{n-1}w_{j}x_{j}\sum_{i=0}^{n-1}w_{i}x_{i}^{2}+3\left(\frac{1}{{\displaystyle \sum_{k=0}^{n-1}}w_{k}}\sum_{j=0}^{n-1}w_{j}x_{j}\right)^{2}\sum_{i=0}^{n-1}w_{i}x_{i}-\left(\frac{1}{{\displaystyle \sum_{k=0}^{n-1}}w_{k}}\sum_{j=0}^{n-1}w_{j}x_{j}\right)^{3}\sum_{i=0}^{n-1}w_{i}\right)\\
 & = & \frac{1}{A}\frac{1}{{\displaystyle \sum_{k=0}^{n-1}}w_{k}}\left({\displaystyle \sum_{k=0}^{n-1}}\sum_{i=0}^{n-1}w_{k}w_{i}x_{i}^{3}-3\sum_{j=0}^{n-1}\sum_{i=0}^{n-1}w_{j}w_{i}x_{j}x_{i}^{2}+2\frac{1}{{\displaystyle \sum_{k=0}^{n-1}}w_{k}}\sum_{j=0}^{n-1}\sum_{k=0}^{n-1}\sum_{i=0}^{n-1}w_{i}w_{j}w_{k}x_{i}x_{j}x_{k}\right)\\
\mathbb{E}[z] & = & \gamma\equiv\mathbb{E}\left[x^{3}\right]-3\mu\sigma^{2}-\mu^{3},\:\text{use }\mathbb{E}\left[x^{3}\right]=\gamma+3\mu\sigma^{2}+\mu^{3}\\
 &  & \frac{1}{A}\frac{1}{{\displaystyle \sum_{k=0}^{n-1}}w_{k}}\left({\displaystyle \sum_{k=0}^{n-1}}\sum_{i=0}^{n-1}w_{k}w_{i}\mathbb{E}\left[x^{3}\right]-3\sum_{j=0}^{n-1}\sum_{i=0}^{n-1}w_{j}w_{i}\mathbb{E}\left[x_{j}x_{i}^{2}\right]+2\frac{1}{{\displaystyle \sum_{k=0}^{n-1}}w_{k}}\sum_{j=0}^{n-1}\sum_{k=0}^{n-1}\sum_{i=0}^{n-1}w_{i}w_{j}w_{k}\mathbb{E}\left[x_{i}x_{j}x_{k}\right]\right).
\end{eqnarray*}

\end_inset

For this we evaluate the triple products
\begin_inset Formula 
\begin{eqnarray*}
\mathbb{E}\left[x_{j}x_{i}^{2}\right] & = & (\gamma+2\mu\sigma^{2})\delta_{ij}+\mu\sigma^{2}+\mu^{3}\\
\mathbb{E}\left[x_{i}x_{j}x_{k}\right] & = & \gamma\delta_{ij}\delta_{ik}+\mu\sigma^{2}(\delta_{ij}+\delta_{jk}+\delta_{ik})+\mu^{3},
\end{eqnarray*}

\end_inset


\series bold
NOTE in error.
 Though the two equations above work, their justification is flawed and
 one must consider covariances between the 
\begin_inset Formula $x_{i},x_{j},[x_{k}]$
\end_inset

.
 Ultimately, the covariances are eliminated (probably because of the odd
 moment) and the they work out.
 This fact complicates the kurtosis calculation.

\series default
 Inserting the triple products
\begin_inset Formula 
\begin{eqnarray*}
\mathbb{E}[z] & = & \frac{1}{A}\frac{\gamma}{\left({\displaystyle \sum_{k=0}^{n-1}}w_{k}\right)^{2}}\left(\left(\sum_{i=0}^{n-1}w_{i}\right)^{3}-3{\displaystyle \sum_{k=0}^{n-1}}w_{k}\sum_{i=0}^{n-1}w_{i}^{2}+2\sum_{i=0}^{n-1}w_{i}^{3}\right).
\end{eqnarray*}

\end_inset

So the unbiased estimator of the third central moment is
\begin_inset Formula 
\begin{eqnarray*}
\hat{\mathbb{E}}[(x-\mu)^{3}] & = & \frac{\left({\displaystyle \sum_{k=0}^{n-1}}w_{k}\right)^{2}\sum_{i=0}^{n-1}w_{i}(x_{i}-\hat{\mu}(x))^{3}}{\left({\displaystyle \sum_{i=0}^{n-1}}w_{i}\right)^{3}-3{\displaystyle \sum_{k=0}^{n-1}}w_{k}{\displaystyle \sum_{i=0}^{n-1}}w_{i}^{2}+2{\displaystyle \sum_{i=0}^{n-1}}w_{i}^{3}}.
\end{eqnarray*}

\end_inset

For the case of equals weights explicitly, we have
\begin_inset Formula 
\begin{eqnarray*}
\hat{\mathbb{E}}[(x-\mu)^{3}] & = & \frac{n^{2}}{(n-1)(n-2)}m_{3}.
\end{eqnarray*}

\end_inset

Expanding the last weighted sum in a manner that shows the cumulants that
 need to be tracked,
\begin_inset Formula 
\begin{eqnarray*}
\hat{\mathbb{E}}[(x-\mu)^{3}] & = & \frac{\left({\displaystyle \sum_{k=0}^{n-1}}w_{k}\right)^{2}{\displaystyle \sum_{i=0}^{n-1}}w_{i}x_{i}^{3}-3{\displaystyle \sum_{k=0}^{n-1}}w_{k}{\displaystyle \sum_{j=0}^{n-1}}w_{j}x_{j}{\displaystyle \sum_{i=0}^{n-1}}w_{i}x_{i}^{2}+2\left({\displaystyle \sum_{j=0}^{n-1}}w_{j}x_{j}\right)^{3}}{\left({\displaystyle \sum_{i=0}^{n-1}}w_{i}\right)^{3}-3{\displaystyle \sum_{k=0}^{n-1}}w_{k}{\displaystyle \sum_{i=0}^{n-1}}w_{i}^{2}+2{\displaystyle \sum_{i=0}^{n-1}}w_{i}^{3}}.
\end{eqnarray*}

\end_inset

So we need to track 
\begin_inset Formula $\sum_{i}w_{i}^{n}$
\end_inset

 and 
\begin_inset Formula $\sum_{i}w_{i}x_{i}^{n}$
\end_inset

 for each of 
\begin_inset Formula $n=1,2,3$
\end_inset

.
 For the case of equal weights 
\begin_inset Formula $w_{i}=w$
\end_inset

,
\begin_inset Formula 
\begin{eqnarray*}
\hat{\mathbb{E}}[(x-\mu)^{3}] & = & \frac{n^{2}{\displaystyle \sum_{i=0}^{n-1}}x_{i}^{3}-3n{\displaystyle \sum_{j=0}^{n-1}}x_{j}{\displaystyle \sum_{i=0}^{n-1}}x_{i}^{2}+2\left({\displaystyle \sum_{j=0}^{n-1}}x_{j}\right)^{3}}{n(n-1)(n-2)}.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsubsection*
double skewness(double * data, size_t n, double * weights)
\end_layout

\begin_layout Standard
Divide the unbiased third central moment devide by the unbiased variance
 to the 3/2 power
\begin_inset Formula 
\begin{eqnarray*}
\frac{\hat{\mathbb{E}}[(x-\mu)^{3}]}{\hat{\sigma}^{3}} & = & \left(\frac{\left({\displaystyle \sum_{i=0}^{n-1}}w_{i}\right)^{2}-{\displaystyle \sum_{i=0}^{n-1}}w_{i}^{2}}{{\displaystyle \sum_{i=0}^{n-1}}w_{i}{\displaystyle \sum_{i=0}^{n-1}}w_{i}x_{i}^{2}-\left({\displaystyle \sum_{j=0}^{n-1}}w_{j}x_{j}\right)^{2}}\right)^{3/2}\frac{\left({\displaystyle \sum_{k=0}^{n-1}}w_{k}\right)^{2}{\displaystyle \sum_{i=0}^{n-1}}w_{i}x_{i}^{3}-3{\displaystyle \sum_{k=0}^{n-1}}w_{k}{\displaystyle \sum_{j=0}^{n-1}}w_{j}x_{j}{\displaystyle \sum_{i=0}^{n-1}}w_{i}x_{i}^{2}+2\left({\displaystyle \sum_{j=0}^{n-1}}w_{j}x_{j}\right)^{3}}{\left({\displaystyle \sum_{i=0}^{n-1}}w_{i}\right)^{3}-3{\displaystyle \sum_{k=0}^{n-1}}w_{k}{\displaystyle \sum_{i=0}^{n-1}}w_{i}^{2}+2{\displaystyle \sum_{i=0}^{n-1}}w_{i}^{3}}.
\end{eqnarray*}

\end_inset

For the case of equal weights,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\frac{\hat{\mathbb{E}}[(x-\mu)^{3}]}{\hat{\sigma}^{3/2}} & = & \frac{n^{3/2}(n-1)^{3/2}}{n(n-1)(n-2)}\frac{n^{2}{\displaystyle \sum_{i=0}^{n-1}}x_{i}^{3}-3n{\displaystyle \sum_{j=0}^{n-1}}x_{j}{\displaystyle \sum_{i=0}^{n-1}}x_{i}^{2}+2\left({\displaystyle \sum_{j=0}^{n-1}}x_{j}\right)^{3}}{\left(n{\displaystyle \sum_{i=0}^{n-1}}x_{i}^{2}-\left({\displaystyle \sum_{j=0}^{n-1}}x_{j}\right)^{2}\right)^{3/2}}.
\end{eqnarray*}

\end_inset

This is the 
\begin_inset Formula $G_{1}$
\end_inset

definition of the sample skewness in the wikipedia article (en.wikipedia.org/wiki/
Skewness).
 Note that whereas this skewness, and really any definition of skewness
 that I can find, is generally a biased estimator for all distributions,
 the third central moment used above and in the part of the definition of
 
\begin_inset Formula $G_{1}$
\end_inset

is an unbiased estimator.
 Therefore skewness should be used with caution.
 Somewhat ironically, all the estimators for skewness in the wikipedia article
 are in fact unbiased and consistent estimator for skewness if the 
\begin_inset Formula $x$
\end_inset

 are normally distributed...which has zero skewness...
\end_layout

\begin_layout Subsubsection*
double fourth_central_moment(double * data, size_t n, double * weights)
\end_layout

\begin_layout Standard
From Cramer 1946, we have 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\hat{\mathbb{E}}[(x-\mu)^{4}] & = & \frac{n(n^{2}-2n+3)m_{4}-2n(2n-3)m_{2}^{2}}{(n-1)(n-2)(n-3)}
\end{eqnarray*}

\end_inset

where
\begin_inset Formula 
\begin{eqnarray*}
m_{k} & = & \frac{1}{n}\sum_{i=0}^{n-1}(x_{i}-\hat{\mu}(x))^{k}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsubsection*
double kurtosis(double * data, size_t n, double * weights)
\end_layout

\begin_layout Standard
Use the fourt_central_moment divided by second (variance) squared
\end_layout

\begin_layout Subsubsection*
double excess_kurtosis(double * data, size_t n, double * weights)
\end_layout

\begin_layout Section*
real_time.h
\end_layout

\begin_layout Standard
Calculations for statistical data from a real-time data stream.
 Specifically to use fast updating algorithms.
 This does not allow for weighted estimates since the updates would be 
\begin_inset Formula $O(n)$
\end_inset

 and all advantage of this module will be lost, i.e.
 there'd be no differene from the 
\begin_inset Quotes eld
\end_inset

basic_statistics.h
\begin_inset Quotes erd
\end_inset

 versions.
 For real-time estimates that include weighting, it would be better to apply
 a filter to the data that approximates the weighting, but this will only
 be exact in special circumstances, e.g.
 exponential or geometrical weighting.
\end_layout

\begin_layout Subsubsection*
int rt_average(double * avg, double new_data, size_t window_size, double_old_dat
a)
\end_layout

\begin_layout Standard
For a window of data, e.g.
 as part of a buffered array 
\begin_inset Formula $d_{i}$
\end_inset

 
\begin_inset Formula $i\in[0,...)$
\end_inset

, the rolling average 
\begin_inset Formula $a_{j}$
\end_inset

 of 
\begin_inset Formula $w=window\_size$
\end_inset

 elements at time 
\begin_inset Formula $j\,(\geq window\_size-1)$
\end_inset

 is
\begin_inset Formula 
\begin{eqnarray*}
a_{j} & = & \frac{1}{w}\sum_{i=j-w+1}^{j}d_{i}\\
 & = & \frac{1}{w}d_{j}+\frac{1}{w}\sum_{i=j-w}^{j-1}d_{i}-\frac{1}{w}d_{j-w},
\end{eqnarray*}

\end_inset

where latest element 
\begin_inset Formula $d_{j}$
\end_inset

 is separated and the additional term from the data point at 
\begin_inset Formula $d_{j-w}$
\end_inset

 has been added/subtracted to allow us to subsitute 
\begin_inset Formula $a_{j-1}=\frac{1}{w}\sum_{i=j-w}^{j-1}d_{i}$
\end_inset

 to get the recurrence relation for the average:
\begin_inset Formula 
\begin{eqnarray*}
a_{j} & = & a_{j-1}+\frac{d_{j}-d_{j-w}}{w}.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard

\series bold
\bar under
Notes:
\end_layout

\begin_layout Itemize
This of course has to be initialized by some means for 
\begin_inset Formula $j<w-1.$
\end_inset

 A simple way to initialize is to artificially use 
\begin_inset Formula $d_{j}=0$
\end_inset

 or 
\begin_inset Formula $d_{j}=d_{0}$
\end_inset

 (or any constant) for 
\begin_inset Formula $j\in[-w,-1]$
\end_inset

 but then the values for 
\begin_inset Formula $a_{j}$
\end_inset

 when 
\begin_inset Formula $j\in[0,w-1]$
\end_inset

 will not match what one might expect.
\end_layout

\begin_layout Itemize
If an error is made, there is no way to fix it and care must be taken that
 if bad data is introduced, it is then removed from the stream in a subsequent
 call by being passed to 
\begin_inset Formula $old\_data$
\end_inset

.
\end_layout

\begin_layout Itemize
window must NOT change while updating the average from the stream
\end_layout

\begin_layout Subsubsection*
int rt_variance(double * var, double * old_mean, double new_data, size_t
 window_size, double old_data)
\end_layout

\begin_layout Standard
Similarly to 
\begin_inset Formula $rt\_average$
\end_inset

, for a window of data, e.g.
 as part of a buffered array 
\begin_inset Formula $d_{i}$
\end_inset

 
\begin_inset Formula $i\in[0,...)$
\end_inset

, the unbiased rolling standard deviation 
\begin_inset Formula $s_{j}$
\end_inset

 of 
\begin_inset Formula $w=window\_size$
\end_inset

 elements at time 
\begin_inset Formula $j\,(\geq window\_size-1)$
\end_inset

 is
\begin_inset Formula 
\begin{eqnarray*}
(w-1)Var_{j}(d) & = & \sum_{i=j-w+1}^{j}(d_{i}-a_{j})^{2}\\
 & = & (d_{j}-a_{j})^{2}-(d_{j-w}-a_{j})^{2}+\sum_{i=j-w}^{j-1}(d_{i}-a_{j})^{2}\\
 & = & (d_{j}-a_{j})^{2}-(d_{j-w}-a_{j})^{2}+\sum_{i=j-w}^{j-1}(d_{i}-a_{j-1}+a_{j-1}-a_{j})^{2}\\
 & = & (d_{j}-a_{j})^{2}-(d_{j-w}-a_{j})^{2}+\sum_{i=j-w}^{j-1}(d_{i}-a_{j-1})^{2}+(a_{j-1}-a_{j})^{2}\sum_{i=j-w}^{j-1}1+(a_{j-1}-a_{j})\sum_{i=j-w}^{j-1}2(d_{i}-a_{j-1}).
\end{eqnarray*}

\end_inset

By recognizing that the last term results in 
\begin_inset Formula $0$
\end_inset

 (the sum of 
\begin_inset Formula $d_{i}$
\end_inset

 is precisely the average 
\begin_inset Formula $a_{j-1}$
\end_inset

), we have
\begin_inset Formula 
\begin{eqnarray*}
Var_{j}(d) & = & Var_{j-1}(d)+\frac{w}{w-1}(a_{j}-a_{j-1})^{2}+\frac{1}{w-1}\left((d_{j}-a_{j})^{2}-(d_{j-w}-a_{j})^{2}\right).
\end{eqnarray*}

\end_inset

If we use the update formula for the average at the same time, we can get
 both the update for the average and standard deviation at the same time.
\end_layout

\begin_layout Standard

\series bold
\bar under
Notes:
\end_layout

\begin_layout Itemize
See rt_average as the same notes apply here
\end_layout

\begin_layout Itemize
\begin_inset Formula $window\_size$
\end_inset

 must be >1
\end_layout

\begin_layout Subsubsection*
int rt_covariance(double * cov_ab, double * old_mean_a, double * old_mean_b,
 double new_data_a, double new_data_b, size_t window_size, double old_data_a,
 double old_data_b)
\end_layout

\begin_layout Standard
Following variance
\begin_inset Formula 
\begin{eqnarray*}
(w-1)Cov_{j}(a,b) & = & \sum_{i=j-w+1}^{j}\left(a_{i}-\hat{\mu}_{j}(a)\right)\left(b_{i}-\hat{\mu}_{j}(b)\right)\\
 & = & \left(a_{j}-\hat{\mu}_{j}(a)\right)\left(b_{j}-\hat{\mu}_{j}(b)\right)-\left(a_{j-w}-\hat{\mu}_{j}(a)\right)\left(b_{j-w}-\hat{\mu}_{j}(b)\right)+\sum_{i=j-w}^{j-1}\left(a_{i}-\hat{\mu}_{j}(a)\right)\left(b_{i}-\hat{\mu}_{j}(b)\right)\\
 & = & N-O+\sum_{i=j-w}^{j-1}\left(a_{i}-\hat{\mu}_{j-1}(a)+\hat{\mu}_{j-1}(a)-\hat{\mu}_{j}(a)\right)\left(b_{i}-\hat{\mu}_{j-1}(b)+\hat{\mu}_{j-1}(b)-\hat{\mu}_{j}(b)\right)\\
 & = & N-O+\sum_{i=j-w}^{j-1}\left(a_{i}-\hat{\mu}_{j-1}(a)\right)\left(b_{i}-\hat{\mu}_{j-1}(b)\right)+\sum_{i=j-w}^{j-1}\left(\hat{\mu}_{j-1}(a)-\hat{\mu}_{j}(a)\right)\left(\hat{\mu}_{j-1}(b)-\hat{\mu}_{j}(b)\right)\\
 &  & +\left(\hat{\mu}_{j-1}(a)-\hat{\mu}_{j}(a)\right)\sum_{i=j-w}^{j-1}\left(b_{i}-\hat{\mu}_{j-1}(b)\right)+\left(\hat{\mu}_{j-1}(b)-\hat{\mu}_{j}(b)\right)\sum_{i=j-w}^{j-1}\left(a_{i}-\hat{\mu}_{j-1}(a)\right)\\
 & = & N-O+(w-1)Cov_{j-1}(a,b)+w\left(\hat{\mu}_{j-1}(a)-\hat{\mu}_{j}(a)\right)\left(\hat{\mu}_{j-1}(b)-\hat{\mu}_{j}(b)\right).
\end{eqnarray*}

\end_inset

Giving us,
\begin_inset Formula 
\begin{eqnarray*}
Cov_{j}(a,b) & = & Cov_{j-1}(a,b)+\frac{\left(a_{j}-\hat{\mu}_{j}(a)\right)\left(b_{j}-\hat{\mu}_{j}(b)\right)-\left(a_{j-w}-\hat{\mu}_{j}(a)\right)\left(b_{j-w}-\hat{\mu}_{j}(b)\right)+w\left(\hat{\mu}_{j-1}(a)-\hat{\mu}_{j}(a)\right)\left(\hat{\mu}_{j-1}(b)-\hat{\mu}_{j}(b)\right)}{w-1}.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsection*
General Moment Updates
\end_layout

\begin_layout Subsubsection*
Moments
\end_layout

\begin_layout Standard
For windowed tracking with window size 
\begin_inset Formula $n$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
a_{p,j} & = & \frac{1}{n}\sum_{i=j-n+1}^{j}x_{i}^{p}\\
 & = & \frac{1}{n}x_{j}^{p}-\frac{1}{n}x_{j-n}^{p}+\frac{1}{n}\sum_{i=j-n}^{j-1}x_{i}^{p}\\
 & = & a_{p,j-1}+\frac{x_{j}^{p}-x_{j-n}^{p}}{n}.
\end{eqnarray*}

\end_inset

For unwindowed moments
\begin_inset Formula 
\begin{eqnarray*}
a_{p,j} & = & \frac{1}{j+1}\sum_{i=0}^{j}x_{i}^{p}\\
 & = & \frac{1}{j+1}x_{j}^{p}+\frac{1}{j+1}\sum_{i=0}^{j-1}x_{i}^{p}=\frac{1}{j+1}x_{j}^{p}+\frac{j}{j+1}\frac{1}{j}\sum_{i=0}^{j-1}x_{i}^{p}\\
 & = & \frac{1}{j+1}x_{j}^{p}+\frac{j}{j+1}a_{p,j-1}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsubsection*
Central Moments
\end_layout

\begin_layout Standard
For windowed tracking with window size 
\begin_inset Formula $n$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
m_{p,j} & = & \frac{1}{n}\sum_{i=j-n+1}^{j}(x_{i}-a_{1,j})^{p}\\
 & = & \frac{1}{n}\sum_{i=j-n+1}^{j}\left((x_{i}-a_{1,j-1})-(a_{1,j}-a_{1,j-1})\right)^{p}\\
 & = & \frac{1}{n}\sum_{i=j-n+1}^{j}\sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(x_{i}-a_{1,j-1})^{p-k}(a_{1,j}-a_{1,j-1})^{k}\\
 & = & \frac{1}{n}\sum_{i=j-n}^{j-1}\sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(x_{i}-a_{1,j-1})^{p-k}(a_{1,j}-a_{1,j-1})^{k}+\frac{1}{n}\sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(a_{1,j}-a_{1,j-1})^{k}\left[(x_{j}-a_{1,j-1})^{p-k}-(x_{j-n}-a_{1,j-1})^{p-k}\right]\\
 & = & \sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(a_{1,j}-a_{1,j-1})^{k}m_{p-k,j-1}+\frac{1}{n}\left[\left((x_{j}-a_{1,j-1}-a_{1j}+a_{1,j-1})^{p}-(x_{j-n}-a_{1,j-1}-a_{1,j}+a_{1,j-1})^{p}\right)\right]\\
 & = & \sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(a_{1,j}-a_{1,j-1})^{k}m_{p-k,j-1}+\frac{1}{n}\left[\left((x_{j}-a_{1j})^{p}-(x_{j-n}-a_{1,j})^{p}\right)\right]\\
 & = & m_{p,j-1}+\sum_{k=1}^{p-2}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(a_{1,j}-a_{1,j-1})^{k}m_{p-k,j-1}+(-1)^{p}(a_{1,j}-a_{1,j-1})^{p}+\frac{1}{n}\left[\left((x_{j}-a_{1j})^{p}-(x_{j-n}-a_{1,j})^{p}\right)\right]
\end{eqnarray*}

\end_inset

As an example for the variance, 
\begin_inset Formula 
\begin{eqnarray*}
m_{2,j} & = & \sum_{k=0}^{2}(-1)^{k}\left(\begin{array}{c}
2\\
k
\end{array}\right)(a_{1,j}-a_{1,j-1})^{k}m_{2-k,j-1}+\frac{1}{n}\left[\left((x_{j}-a_{1j})^{2}-(x_{j-n}-a_{1,j})^{2}\right)\right]\\
 & = & m_{2,j-1}-2(a_{1,j}-a_{1,j-1})m_{1,j-1}+(a_{1,j}-a_{1,j-1})^{2}m_{0,j-1}+\frac{1}{n}\left[\left((x_{j}-a_{1j})^{2}-(x_{j-n}-a_{1,j})^{2}\right)\right]\\
 & = & m_{2,j-1}+(a_{1,j}-a_{1,j-1})^{2}+\frac{1}{n}\left[\left((x_{j}-a_{1j})^{2}-(x_{j-n}-a_{1,j})^{2}\right)\right]
\end{eqnarray*}

\end_inset

using 
\begin_inset Formula $m_{1,j}=0$
\end_inset

 and 
\begin_inset Formula $m_{0,j}=1\forall j$
\end_inset

 exactly as we have above without Bessel's correction.
 Applying these simplifications to the general case,
\begin_inset Formula 
\begin{eqnarray*}
m_{p,j} & = & m_{p,j-1}+(-1)^{p}(a_{1,j}-a_{1,j-1})^{p}+\frac{1}{n}\left[\left((x_{j}-a_{1j})^{p}-(x_{j-n}-a_{1,j})^{p}\right)\right]+\sum_{k=1}^{p-2}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(a_{1,j}-a_{1,j-1})^{k}m_{p-k,j-1}
\end{eqnarray*}

\end_inset

where the last term is only applicable for 
\begin_inset Formula $p>2.$
\end_inset

 The unbiased moments 
\begin_inset Formula $M_{p,j}$
\end_inset

 can be updated provided 
\begin_inset Formula $m_{p,j}$
\end_inset

 are already calculated.
 The central moments themselves only depend on the estimates of the means
 so that the moments 
\begin_inset Formula $a_{p,j}$
\end_inset

 
\begin_inset Formula $p>1$
\end_inset

 are not actually required for any of the statistics
\end_layout

\begin_layout Standard
For unwindowed sampling (or starting windowed sampling with current sample
 count 
\begin_inset Formula $m<n$
\end_inset

),
\begin_inset Formula 
\begin{eqnarray*}
m_{p,j} & = & \frac{1}{j+1}\sum_{i=0}^{j}(x_{i}-a_{1,j})^{p}\\
 & = & \frac{1}{j+1}\sum_{i=0}^{j}\left((x_{i}-a_{1,j-1})-(a_{1,j}-a_{1,j-1})\right)^{p}\\
 & = & \frac{1}{j+1}\sum_{i=0}^{j}\sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(x_{i}-a_{1,j-1})^{p-k}(a_{1,j}-a_{1,j-1})^{k}\\
 & = & \frac{j}{j+1}\sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)\frac{1}{j}\sum_{i=0}^{j-1}(x_{i}-a_{1,j-1})^{p-k}(a_{1,j}-a_{1,j-1})^{k}+\frac{1}{j+1}\sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(x_{j}-a_{1,j-1})^{p-k}(a_{1,j}-a_{1,j-1})^{k}\\
 & = & \frac{j}{j+1}\sum_{k=0}^{p}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(a_{1,j}-a_{1,j-1})^{k}m_{p-k,j-1}+\frac{1}{j+1}\left(x_{j}-a_{1,j}\right)^{p}\\
 & = & \frac{j}{j+1}m_{p,j-1}+\frac{j}{j+1}(-1)^{p}(a_{1,j}-a_{1,j-1})^{p}+\frac{j}{j+1}\sum_{k=1}^{p-2}(-1)^{k}\left(\begin{array}{c}
p\\
k
\end{array}\right)(a_{1,j}-a_{1,j-1})^{k}m_{p-k,j-1}+\frac{1}{j+1}\left(x_{j}-a_{1,j}\right)^{p}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Section*
General expectations
\end_layout

\end_body
\end_document
